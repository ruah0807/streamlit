import streamlit as st
from langchain_chroma import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from pdfminer.high_level import extract_pages 
from pdfminer.layout import LTTextContainer 
from langchain.docstore.document import Document
from config_beta_kw import *
import os
import pprint

embeddings = HuggingFaceEmbeddings(
    model_name=bgeEMBED_MODEL,
    model_kwargs={'device': 'cuda'},
    encode_kwargs={'normalize_embeddings': True}
    )

@st.cache_resource
def get_vectorstore():
    return Chroma(persist_directory=Pm_Persist_directory, embedding_function=embeddings)

def extract_text_by_page(pdf_path): 
    try:
        for page_layout in extract_pages(pdf_path): 
            page_text = "" 
            for element in page_layout: 
                if isinstance(element, LTTextContainer): 
                    page_text += element.get_text() 
            yield page_text 
    except FileNotFoundError:
        st.error(f"Error: The file '{pdf_path}' was not found.")
        return -1
    # PDF ë¬¸ì„œ êµ¬ì¡°ì— ë¬¸ì œê°€ ìˆëŠ” ê²½ìš° (ì˜ëª»ëœ PDF í˜•ì‹ ë“±)
    except Exception as e:
        st.error(f"An unexpected error: {e}")
        return -1

##
def trim_data(mdata):
    # ê²½ë¡œì—ì„œ íŒŒì¼ ì´ë¦„ ì¶”ì¶œ
    file_name = os.path.basename(mdata)
    # íŒŒì¼ ì´ë¦„ì„ ì œì™¸í•œ ê²½ë¡œ ì¶”ì¶œ
    dir_path = os.path.dirname(mdata)
    # ë§ˆì§€ë§‰ ë””ë ‰í† ë¦¬ ì¶”ì¶œ
    last_directory = os.path.basename(dir_path)
    # ë§ˆì§€ë§‰ ë””ë ‰í† ë¦¬ì™€ íŒŒì¼ ì´ë¦„ì„ ê²°í•©í•˜ì—¬ ìƒˆë¡œìš´ ê²½ë¡œ ìƒì„±
    modified_path = os.path.join(last_directory, file_name)
    return modified_path    

def pdf_reader(pdfname):
    st.markdown(f"ğŸ‘‰ : {trim_data(pdfname)}", unsafe_allow_html=True)
    
    documents = []
    for page_num, page_text in enumerate(extract_text_by_page(pdfname), start=1): 
        # í˜ì´ì§€ ë²ˆí˜¸ì™€ íŒŒì¼ëª…ì„ ë©”íƒ€ë°ì´í„°ë¡œ ì¶”ê°€í•˜ì—¬ ë¬¸ì„œ ìƒì„±
        if page_text == -1:
            return page_text
        metadata = {"page": page_num, "source": pdfname}
        #pprint.pprint(f'page === {page_num} \n {page_text}')
        documents.append(Document(page_content=page_text, metadata=metadata))   
    #pprint.pprint(f'pdfminer = {documents.page_content}')
    text_splitter = RecursiveCharacterTextSplitter(chunk_size= CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)
    texts = text_splitter.split_documents(documents)
    return texts

##
def db_input(fname):
    file_ext = os.path.splitext(fname)[-1].lower()  # íŒŒì¼ í™•ì¥ì(.pdf)
    # extension = extensions.get(file_ext)  

    if os.path.isdir(Pm_Persist_directory):  # dbê°€ ì´ë¯¸ ìƒì„±ë˜ì–´ìˆëŠ”ê°€?
        _vectordb = get_vectorstore()
        result = _vectordb.get(where={'source':  fname })
        if 'ids' in result and result['ids']:
           st.markdown(f'ğŸ‘‰ : {trim_data(fname)} __embedded !!', unsafe_allow_html=True)
           return False
    else:
        st.markdown(f"**DB ìµœì´ˆ ìƒì„±** : {Pm_Persist_directory}")

    if file_ext == ".pdf":
        texts = pdf_reader(fname)
        if texts == -1:
            return False
    else:
        st.error("file corruption")
        return False

    try:
        with st.spinner("DB creation in progress...."):
            Chroma.from_documents(
                documents=texts,
                embedding=embeddings,
                persist_directory=Pm_Persist_directory)
            return True
    except Exception as e:
        st.error(f"DB write ì˜¤ë¥˜:{fname} : {e}")
        return False

##
def read_docs_in_directory(directory):
    # extensions = [".pdf", ".hwp", ".csv"]
    extensions = [".pdf"]    # CSV íŒŒì¼ DBëŠ” ë³„ë„ë¡œ ìƒì„±í•¨
    # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ì— ëª¨ë“  íŒŒì¼ ì°¾ê¸°
    f_count = 0
    for file in os.listdir(directory):
        file_ext = os.path.splitext(file)[-1].lower()
        if file_ext in extensions:
            docs_file = os.path.join(directory, file)
            if db_input(docs_file) == True:
                f_count += 1
                st.markdown(f'success __{str(f_count)} ')
        else:
            st.error(f"íŒŒì¼ í˜•ì‹ì˜¤ë¥˜ : {file}")
            continue
    return f_count

##
def make_db(dir_name):
    full_path = os.path.join(DOCUMENTs, dir_name)
    file_num = read_docs_in_directory(full_path)
    #result_p.markdown(f'ë””ë ‰í† ë¦¬ :blue[{full_path}] __íŒŒì¼ {str(file_num)}ê°œ DBì— ì¶”ê°€ë¨.')
    st.markdown(f'â˜° :blue[ë””ë ‰í† ë¦¬ {full_path}] __íŒŒì¼ {str(file_num)}ê°œ DBì— ì¶”ê°€ë¨.')

